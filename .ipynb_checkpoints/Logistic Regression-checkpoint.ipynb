{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as ny\n",
    "from numpy import *\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data = iris[\"data\"]\n",
    "labels = iris[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import math\n",
    "# import numpy as ny\n",
    "# from numpy import *\n",
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# from sklearn import datasets\n",
    "\n",
    "# from __future__ import division\n",
    "# import numpy as np\n",
    "# import scipy\n",
    "# from scipy import linalg as la\n",
    "# import math\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# lrclassfier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10.0, fit_intercept=True, intercept_scaling=1)\n",
    "# classifier = lrclassfier.fit(data, labels)\n",
    "# predicted_set = classifier.predict(data)\n",
    "\n",
    "# for i in zip(labels, predicted_set):\n",
    "#     print(i[0],i[1],i[0]==i[1])\n",
    "\n",
    "# print('Accuracy on training data: ',(np.sum(predicted_set == labels)/len(labels))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Logistic Regression classifier class\n",
    "'''\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "from scipy.optimize import fmin_bfgs\n",
    "# import bigfloat\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, data, labels, alpha = 1, num_iters = 100):\n",
    "        self.num_iters = num_iters\n",
    "        self.alpha = alpha\n",
    "\n",
    "\n",
    "    def train(self, data, Olabels, unique_classes):\n",
    "        '''\n",
    "        train the classifier. One classifier per unique label\n",
    "        '''\n",
    "        print 'training....'\n",
    "        debug = self.debug\n",
    "        regularized = self.regularized\n",
    "        #print 'train regularized', regularized\n",
    "\n",
    "        num_iters = self.num_iters\n",
    "        m,n = data.shape\n",
    "\n",
    "        # map labels to program friendly labels\n",
    "        labels = np.zeros(Olabels.shape)\n",
    "        \n",
    "        uniq_Olabel_names = np.unique(Olabels)\n",
    "\n",
    "        uniq_label_list = range(len(uniq_Olabel_names))\n",
    "\n",
    "        for each in zip(uniq_Olabel_names, uniq_label_list):\n",
    "            o_label_name = each[0]\n",
    "            new_label_name = each[1]\n",
    "            labels[np.where(Olabels == o_label_name)] = new_label_name\n",
    "\n",
    "        labels = labels.reshape((len(labels),1))\n",
    "        # now labels variable contains labels starting from 0 to (num_classes -1)\n",
    "        #print unique_classes\n",
    "        num_classes = len(unique_classes)\n",
    "\n",
    "        Init_Thetas = [] # to hold initial values of theta\n",
    "        \n",
    "        Thetas = [] # to hold final values of theta to return\n",
    "        \n",
    "        Cost_Thetas = [] # cost associated with each theta\n",
    "        \n",
    "        Cost_History_Theta = [] # contains list of varying cost thetas\n",
    "        \n",
    "        # if num_classes = 2, then N_Thetas will contain only 1 Theta\n",
    "        # if num_classes >2, then N_Thetas will contain num_classes number of Thetas.\n",
    "\n",
    "        \n",
    "        if(num_classes == 2):\n",
    "            theta_init = np.zeros((n,1))\n",
    "             Init_Thetas.append(theta_init)\n",
    "            \n",
    "            # we need only 1 theta to classify class A from class B\n",
    "            #local_labels = np.zeros(labels.shape)\n",
    "            #local_labels[np.where(labels == 2)] = 1\n",
    "            # for i in zip(labels, local_labels):\n",
    "                        # \tprin\n",
    "            # exit()\n",
    "        \n",
    "            local_labels = labels\n",
    "\n",
    "            assert(len(np.unique(labels)) == 2)\n",
    "             \n",
    "            assert(len(local_labels) == len(labels))\n",
    "             \n",
    "                         init_theta = Init_Thetas[0]\n",
    "\n",
    "            new_theta, final_cost = self.computeGradient(data, local_labels, init_theta)\n",
    "        \n",
    "            Thetas.append(new_theta)\n",
    "            Cost_Thetas.append(final_cost)\n",
    "\n",
    "        elif(num_classes>2):\n",
    "             for eachInitTheta in range(num_classes):\n",
    " \t\t\t\ttheta_init = np.zeros((n,1))\n",
    " \t\t\t\tInit_Thetas.append(theta_init)\n",
    " \t\t\t\tpass\n",
    "\n",
    "\t \t\tfor eachClass in range(num_classes):\n",
    "                    # load data local of the init_theta\n",
    "                    # +ve class is 1 and rest are zeros\n",
    "                    # its a one vs all classifier\n",
    "\n",
    "                    local_labels = np.zeros(labels.shape)\n",
    "\n",
    "                    \n",
    "                    local_labels[np.where(labels == eachClass)] = 1\n",
    "\t \t\t\n",
    "\n",
    "                    # assert to make sure that its true\n",
    "                    assert(len(np.unique(local_labels)) == 2)\n",
    "                    assert(len(local_labels) == len(labels))\n",
    "                    # print eachClass\t\n",
    "                    # print Init_Thetas\n",
    "                init_theta = Init_Thetas[eachClass]\n",
    "\n",
    "                \n",
    "                new_theta, final_cost = self.computeGradient(data, local_labels, init_theta)\n",
    "                #print final_cost\n",
    "                Thetas.append(new_theta)\n",
    "                Cost_Thetas.append(final_cost)\n",
    "\t\t\t\n",
    "\t\treturn Thetas, Cost_Thetas\n",
    "\t\n",
    "\n",
    "\tdef classify(self, data, Thetas):\n",
    "        '''\n",
    "        classify given data and return a list of associated classified labels\n",
    "        '''\n",
    "        # since it is a one values all classifier, load all classifiers and pick most likely\n",
    "        # i.e. which gives max value for sigmoid(X*theta)\n",
    "        debug = self.debug\n",
    "        assert(len(Thetas)>0)\n",
    "        \n",
    "        if(len(Thetas) > 1):\n",
    "\t\t\tmvals = []\t\n",
    "\t\t\tfor eachTheta in Thetas:\n",
    "\t\t\t\tmvals.append(self.sigmoidCalc(np.dot(data, eachTheta)))\n",
    "\n",
    "\t\t\t\tpass\n",
    "\t\t\treturn mvals.index(max(mvals))+1\n",
    "\n",
    "        elif(len(Thetas) == 1):\n",
    "\t\t\t# either is close to zero or 1\n",
    "\t\t\t# if more than 0.5 classify as 1 and if less than 0.5 classify as 0\n",
    "\t\t\t# print data\n",
    "\t\t\t# print Thetas[0]\n",
    "\t\t\t#print self.sigmoidCalc(np.dot(data, Thetas[0]))\n",
    "\n",
    "\t\t\tcval = round(self.sigmoidCalc(np.dot(data, Thetas[0])))+1.0\n",
    "\t\t\t#print 'classification output: ', cval\t\n",
    "\t\t\treturn cval\n",
    "\n",
    "\t\n",
    "\tdef sigmoidCalc(self, data):\n",
    "        '''\n",
    "        calculate the sigmoid of the given data\n",
    "        '''\n",
    "        # if(len(data.flatten()) == 1 ):\n",
    "        # \tdata = data.reshape((1,1))\n",
    "        debug = self.debug\n",
    "        data = np.array(data, dtype = np.longdouble)\n",
    "        #g = np.zeros(data.shape, dtype = np.float64)\n",
    "        g = 1/(1+np.exp(-data))\n",
    "        \n",
    "\t\treturn g\n",
    "\n",
    "\tdef computeCost(self,data, labels, init_theta):\n",
    "        '''\n",
    "        compute cost of the given value of theta and return it\n",
    "        '''\n",
    "        debug = self.debug\n",
    "        regularized = self.regularized\n",
    "        if(regularized == True):\n",
    "\t\t\tllambda = 1.0\n",
    "\t\t\t#print 'using llambda', llambda\n",
    "        else:\n",
    "\t\t\tllambda = 0\n",
    "\n",
    "        m,n = data.shape\n",
    "        \n",
    "        J = 0\n",
    "\n",
    "\t\tgrad = np.zeros(init_theta.shape)\n",
    "\n",
    "\t\ttheta2 = init_theta[range(1,init_theta.shape[0]),:]\n",
    "\t\tif(self.normalization_mode == \"l1\"):\n",
    "            regularized_parameter = np.dot(llambda/(2*m), np.sum( np.abs(theta2)))\n",
    "            # print 'mode: ', self.normalization_mode\n",
    "            # print 'lambda: ', llambda\n",
    "            # print regularized_parameter\n",
    "        else:\n",
    "            #(self.mode == \"l2\")\n",
    "            regularized_parameter = np.dot(llambda/(2*m), np.sum( theta2 * theta2))\n",
    "            # print 'mode: ', self.normalization_mode\n",
    "            # print 'lambda: ', llambda\n",
    "            # print regularized_parameter\n",
    "        \n",
    "\t\t\n",
    "        J = (-1.0/ m) * ( np.sum( np.log(self.sigmoidCalc( np.dot(data, init_theta))) * labels + ( np.log ( 1 - self.sigmoidCalc(np.dot(data, init_theta)) ) * ( 1 - labels ) )))\n",
    "              \n",
    "        J = J + regularized_parameter\n",
    "        #print 'llambda, regularized parameter: ', llambda, regularized_parameter\n",
    "        return J\n",
    "\n",
    "\tdef computeGradient(self,data, labels, init_theta):\n",
    "        alpha = self.alpha\n",
    "        debug = self.debug\n",
    "        num_iters = self.num_iters\n",
    "        m,n = data.shape\n",
    "        regularized = self.regularized\n",
    "\n",
    "        #print 'inoming regularized', regularized\n",
    "        if(regularized == True):\n",
    "\t\t\tllambda = 1\n",
    "        else:        \n",
    "\t\t\tllambda = 0\n",
    "                        \n",
    "        for eachIteration in range(num_iters):\n",
    "            cost = self.computeCost(data, labels, init_theta)\n",
    "            if(debug):\n",
    "                print 'iteration: ', eachIteration\n",
    "                print 'cost: ', cost\n",
    "                \n",
    "            #compute gradient\n",
    "            \n",
    "            B = self.sigmoidCalc(np.dot(data, init_theta) - labels)\n",
    "            \n",
    "            A = (1/m)*np.transpose(data)\n",
    "            \n",
    "            grad = np.dot(A,B)\n",
    "            \n",
    "            \n",
    "            A = (self.sigmoidCalc(np.dot(data, init_theta)) - labels )\n",
    "            B =  data[:,0].reshape((data.shape[0],1))\n",
    "            \n",
    "            grad[0] = (1/m) * np.sum(A*B)\n",
    "                            \n",
    "            A = (self.sigmoidCalc(np.dot(data, init_theta)) - labels)\n",
    "            B = (data[:,range(1,n)])\n",
    "            \n",
    "            for i in range(1, len(grad)):\n",
    "\t\t\t\tA = (self.sigmoidCalc(np.dot(data,init_theta)) - labels )\n",
    "\t\t\t\tB = (data[:,i].reshape((data[:,i].shape[0],1)))\n",
    "\t\t\t\tgrad[i] = (1/m)*np.sum(A*B) + ((llambda/m)*init_theta[i])\n",
    "\n",
    "\n",
    "\t\t\t\t\t\t\n",
    "\t\t\tinit_theta = init_theta - (np.dot((alpha/m), grad))\n",
    "\t\t\t        \n",
    "        return init_theta, cost\n",
    "\n",
    "\tdef mapper(self):\n",
    "\t\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
